// Code generated by ent, DO NOT EDIT.

package ent

import (
	"context"
	"database/sql/driver"
	"fmt"

	"entgo.io/contrib/entgql"
	"entgo.io/ent/dialect/sql"
	"github.com/99designs/gqlgen/graphql"
	"realm.pub/tavern/internal/ent/beacon"
	"realm.pub/tavern/internal/ent/file"
	"realm.pub/tavern/internal/ent/host"
	"realm.pub/tavern/internal/ent/hostcredential"
	"realm.pub/tavern/internal/ent/hostfile"
	"realm.pub/tavern/internal/ent/hostprocess"
	"realm.pub/tavern/internal/ent/portal"
	"realm.pub/tavern/internal/ent/quest"
	"realm.pub/tavern/internal/ent/repository"
	"realm.pub/tavern/internal/ent/shell"
	"realm.pub/tavern/internal/ent/tag"
	"realm.pub/tavern/internal/ent/task"
	"realm.pub/tavern/internal/ent/tome"
	"realm.pub/tavern/internal/ent/user"
)

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (b *BeaconQuery) CollectFields(ctx context.Context, satisfies ...string) (*BeaconQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return b, nil
	}
	if err := b.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return b, nil
}

func (b *BeaconQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(beacon.Columns))
		selectedFields = []string{beacon.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "host":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&HostClient{config: b.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, hostImplementors)...); err != nil {
				return err
			}
			b.withHost = query

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: b.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					b.loadTotal = append(b.loadTotal, func(ctx context.Context, nodes []*Beacon) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"task_beacon"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(beacon.TasksColumn), ids...))
						})
						if err := query.GroupBy(beacon.TasksColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					b.loadTotal = append(b.loadTotal, func(_ context.Context, nodes []*Beacon) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(beacon.TasksColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			b.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "shells":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ShellClient{config: b.config}).Query()
			)
			args := newShellPaginateArgs(fieldArgs(ctx, new(ShellWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newShellPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					b.loadTotal = append(b.loadTotal, func(ctx context.Context, nodes []*Beacon) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"shell_beacon"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(beacon.ShellsColumn), ids...))
						})
						if err := query.GroupBy(beacon.ShellsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					b.loadTotal = append(b.loadTotal, func(_ context.Context, nodes []*Beacon) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Shells)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, shellImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(beacon.ShellsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			b.WithNamedShells(alias, func(wq *ShellQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[beacon.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, beacon.FieldCreatedAt)
				fieldSeen[beacon.FieldCreatedAt] = struct{}{}
			}
		case "lastModifiedAt":
			if _, ok := fieldSeen[beacon.FieldLastModifiedAt]; !ok {
				selectedFields = append(selectedFields, beacon.FieldLastModifiedAt)
				fieldSeen[beacon.FieldLastModifiedAt] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[beacon.FieldName]; !ok {
				selectedFields = append(selectedFields, beacon.FieldName)
				fieldSeen[beacon.FieldName] = struct{}{}
			}
		case "principal":
			if _, ok := fieldSeen[beacon.FieldPrincipal]; !ok {
				selectedFields = append(selectedFields, beacon.FieldPrincipal)
				fieldSeen[beacon.FieldPrincipal] = struct{}{}
			}
		case "identifier":
			if _, ok := fieldSeen[beacon.FieldIdentifier]; !ok {
				selectedFields = append(selectedFields, beacon.FieldIdentifier)
				fieldSeen[beacon.FieldIdentifier] = struct{}{}
			}
		case "agentIdentifier":
			if _, ok := fieldSeen[beacon.FieldAgentIdentifier]; !ok {
				selectedFields = append(selectedFields, beacon.FieldAgentIdentifier)
				fieldSeen[beacon.FieldAgentIdentifier] = struct{}{}
			}
		case "lastSeenAt":
			if _, ok := fieldSeen[beacon.FieldLastSeenAt]; !ok {
				selectedFields = append(selectedFields, beacon.FieldLastSeenAt)
				fieldSeen[beacon.FieldLastSeenAt] = struct{}{}
			}
		case "nextSeenAt":
			if _, ok := fieldSeen[beacon.FieldNextSeenAt]; !ok {
				selectedFields = append(selectedFields, beacon.FieldNextSeenAt)
				fieldSeen[beacon.FieldNextSeenAt] = struct{}{}
			}
		case "interval":
			if _, ok := fieldSeen[beacon.FieldInterval]; !ok {
				selectedFields = append(selectedFields, beacon.FieldInterval)
				fieldSeen[beacon.FieldInterval] = struct{}{}
			}
		case "transport":
			if _, ok := fieldSeen[beacon.FieldTransport]; !ok {
				selectedFields = append(selectedFields, beacon.FieldTransport)
				fieldSeen[beacon.FieldTransport] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		b.Select(selectedFields...)
	}
	return nil
}

type beaconPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []BeaconPaginateOption
}

func newBeaconPaginateArgs(rv map[string]any) *beaconPaginateArgs {
	args := &beaconPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*BeaconOrder:
			args.opts = append(args.opts, WithBeaconOrder(v))
		case []any:
			var orders []*BeaconOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &BeaconOrder{Field: &BeaconOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithBeaconOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*BeaconWhereInput); ok {
		args.opts = append(args.opts, WithBeaconFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (f *FileQuery) CollectFields(ctx context.Context, satisfies ...string) (*FileQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return f, nil
	}
	if err := f.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return f, nil
}

func (f *FileQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(file.Columns))
		selectedFields = []string{file.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "tomes":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TomeClient{config: f.config}).Query()
			)
			args := newTomePaginateArgs(fieldArgs(ctx, new(TomeWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTomePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					f.loadTotal = append(f.loadTotal, func(ctx context.Context, nodes []*File) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"file_id"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(file.TomesTable)
							s.Join(joinT).On(s.C(tome.FieldID), joinT.C(file.TomesPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(file.TomesPrimaryKey[1]), ids...))
							s.Select(joinT.C(file.TomesPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(file.TomesPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				} else {
					f.loadTotal = append(f.loadTotal, func(_ context.Context, nodes []*File) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tomes)
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, tomeImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(file.TomesPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			f.WithNamedTomes(alias, func(wq *TomeQuery) {
				*wq = *query
			})

		case "links":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&LinkClient{config: f.config}).Query()
			)
			args := newLinkPaginateArgs(fieldArgs(ctx, new(LinkWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newLinkPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					f.loadTotal = append(f.loadTotal, func(ctx context.Context, nodes []*File) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"link_file"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(file.LinksColumn), ids...))
						})
						if err := query.GroupBy(file.LinksColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					f.loadTotal = append(f.loadTotal, func(_ context.Context, nodes []*File) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Links)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, linkImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(file.LinksColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			f.WithNamedLinks(alias, func(wq *LinkQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[file.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, file.FieldCreatedAt)
				fieldSeen[file.FieldCreatedAt] = struct{}{}
			}
		case "lastModifiedAt":
			if _, ok := fieldSeen[file.FieldLastModifiedAt]; !ok {
				selectedFields = append(selectedFields, file.FieldLastModifiedAt)
				fieldSeen[file.FieldLastModifiedAt] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[file.FieldName]; !ok {
				selectedFields = append(selectedFields, file.FieldName)
				fieldSeen[file.FieldName] = struct{}{}
			}
		case "size":
			if _, ok := fieldSeen[file.FieldSize]; !ok {
				selectedFields = append(selectedFields, file.FieldSize)
				fieldSeen[file.FieldSize] = struct{}{}
			}
		case "hash":
			if _, ok := fieldSeen[file.FieldHash]; !ok {
				selectedFields = append(selectedFields, file.FieldHash)
				fieldSeen[file.FieldHash] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		f.Select(selectedFields...)
	}
	return nil
}

type filePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []FilePaginateOption
}

func newFilePaginateArgs(rv map[string]any) *filePaginateArgs {
	args := &filePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*FileOrder:
			args.opts = append(args.opts, WithFileOrder(v))
		case []any:
			var orders []*FileOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &FileOrder{Field: &FileOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithFileOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*FileWhereInput); ok {
		args.opts = append(args.opts, WithFileFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (h *HostQuery) CollectFields(ctx context.Context, satisfies ...string) (*HostQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return h, nil
	}
	if err := h.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return h, nil
}

func (h *HostQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(host.Columns))
		selectedFields = []string{host.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "tags":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TagClient{config: h.config}).Query()
			)
			args := newTagPaginateArgs(fieldArgs(ctx, new(TagWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTagPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					h.loadTotal = append(h.loadTotal, func(ctx context.Context, nodes []*Host) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"host_id"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(host.TagsTable)
							s.Join(joinT).On(s.C(tag.FieldID), joinT.C(host.TagsPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(host.TagsPrimaryKey[0]), ids...))
							s.Select(joinT.C(host.TagsPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(host.TagsPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				} else {
					h.loadTotal = append(h.loadTotal, func(_ context.Context, nodes []*Host) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tags)
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, tagImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(host.TagsPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			h.WithNamedTags(alias, func(wq *TagQuery) {
				*wq = *query
			})

		case "beacons":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&BeaconClient{config: h.config}).Query()
			)
			args := newBeaconPaginateArgs(fieldArgs(ctx, new(BeaconWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newBeaconPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					h.loadTotal = append(h.loadTotal, func(ctx context.Context, nodes []*Host) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"beacon_host"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(host.BeaconsColumn), ids...))
						})
						if err := query.GroupBy(host.BeaconsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					h.loadTotal = append(h.loadTotal, func(_ context.Context, nodes []*Host) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Beacons)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, beaconImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(host.BeaconsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			h.WithNamedBeacons(alias, func(wq *BeaconQuery) {
				*wq = *query
			})

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&HostFileClient{config: h.config}).Query()
			)
			args := newHostFilePaginateArgs(fieldArgs(ctx, new(HostFileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newHostFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					h.loadTotal = append(h.loadTotal, func(ctx context.Context, nodes []*Host) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"host_files"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(host.FilesColumn), ids...))
						})
						if err := query.GroupBy(host.FilesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					h.loadTotal = append(h.loadTotal, func(_ context.Context, nodes []*Host) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, hostfileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(host.FilesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			h.WithNamedFiles(alias, func(wq *HostFileQuery) {
				*wq = *query
			})

		case "processes":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&HostProcessClient{config: h.config}).Query()
			)
			args := newHostProcessPaginateArgs(fieldArgs(ctx, new(HostProcessWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newHostProcessPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					h.loadTotal = append(h.loadTotal, func(ctx context.Context, nodes []*Host) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"host_processes"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(host.ProcessesColumn), ids...))
						})
						if err := query.GroupBy(host.ProcessesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					h.loadTotal = append(h.loadTotal, func(_ context.Context, nodes []*Host) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Processes)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, hostprocessImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(host.ProcessesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			h.WithNamedProcesses(alias, func(wq *HostProcessQuery) {
				*wq = *query
			})

		case "credentials":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&HostCredentialClient{config: h.config}).Query()
			)
			args := newHostCredentialPaginateArgs(fieldArgs(ctx, new(HostCredentialWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newHostCredentialPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					h.loadTotal = append(h.loadTotal, func(ctx context.Context, nodes []*Host) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"host_credential_host"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(host.CredentialsColumn), ids...))
						})
						if err := query.GroupBy(host.CredentialsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					h.loadTotal = append(h.loadTotal, func(_ context.Context, nodes []*Host) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Credentials)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, hostcredentialImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(host.CredentialsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			h.WithNamedCredentials(alias, func(wq *HostCredentialQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[host.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, host.FieldCreatedAt)
				fieldSeen[host.FieldCreatedAt] = struct{}{}
			}
		case "lastModifiedAt":
			if _, ok := fieldSeen[host.FieldLastModifiedAt]; !ok {
				selectedFields = append(selectedFields, host.FieldLastModifiedAt)
				fieldSeen[host.FieldLastModifiedAt] = struct{}{}
			}
		case "identifier":
			if _, ok := fieldSeen[host.FieldIdentifier]; !ok {
				selectedFields = append(selectedFields, host.FieldIdentifier)
				fieldSeen[host.FieldIdentifier] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[host.FieldName]; !ok {
				selectedFields = append(selectedFields, host.FieldName)
				fieldSeen[host.FieldName] = struct{}{}
			}
		case "primaryIP":
			if _, ok := fieldSeen[host.FieldPrimaryIP]; !ok {
				selectedFields = append(selectedFields, host.FieldPrimaryIP)
				fieldSeen[host.FieldPrimaryIP] = struct{}{}
			}
		case "externalIP":
			if _, ok := fieldSeen[host.FieldExternalIP]; !ok {
				selectedFields = append(selectedFields, host.FieldExternalIP)
				fieldSeen[host.FieldExternalIP] = struct{}{}
			}
		case "platform":
			if _, ok := fieldSeen[host.FieldPlatform]; !ok {
				selectedFields = append(selectedFields, host.FieldPlatform)
				fieldSeen[host.FieldPlatform] = struct{}{}
			}
		case "lastSeenAt":
			if _, ok := fieldSeen[host.FieldLastSeenAt]; !ok {
				selectedFields = append(selectedFields, host.FieldLastSeenAt)
				fieldSeen[host.FieldLastSeenAt] = struct{}{}
			}
		case "nextSeenAt":
			if _, ok := fieldSeen[host.FieldNextSeenAt]; !ok {
				selectedFields = append(selectedFields, host.FieldNextSeenAt)
				fieldSeen[host.FieldNextSeenAt] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		h.Select(selectedFields...)
	}
	return nil
}

type hostPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []HostPaginateOption
}

func newHostPaginateArgs(rv map[string]any) *hostPaginateArgs {
	args := &hostPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*HostOrder:
			args.opts = append(args.opts, WithHostOrder(v))
		case []any:
			var orders []*HostOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &HostOrder{Field: &HostOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithHostOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*HostWhereInput); ok {
		args.opts = append(args.opts, WithHostFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (hc *HostCredentialQuery) CollectFields(ctx context.Context, satisfies ...string) (*HostCredentialQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return hc, nil
	}
	if err := hc.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return hc, nil
}

func (hc *HostCredentialQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(hostcredential.Columns))
		selectedFields = []string{hostcredential.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "host":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&HostClient{config: hc.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, hostImplementors)...); err != nil {
				return err
			}
			hc.withHost = query

		case "task":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: hc.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
				return err
			}
			hc.withTask = query
		case "createdAt":
			if _, ok := fieldSeen[hostcredential.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, hostcredential.FieldCreatedAt)
				fieldSeen[hostcredential.FieldCreatedAt] = struct{}{}
			}
		case "lastModifiedAt":
			if _, ok := fieldSeen[hostcredential.FieldLastModifiedAt]; !ok {
				selectedFields = append(selectedFields, hostcredential.FieldLastModifiedAt)
				fieldSeen[hostcredential.FieldLastModifiedAt] = struct{}{}
			}
		case "principal":
			if _, ok := fieldSeen[hostcredential.FieldPrincipal]; !ok {
				selectedFields = append(selectedFields, hostcredential.FieldPrincipal)
				fieldSeen[hostcredential.FieldPrincipal] = struct{}{}
			}
		case "secret":
			if _, ok := fieldSeen[hostcredential.FieldSecret]; !ok {
				selectedFields = append(selectedFields, hostcredential.FieldSecret)
				fieldSeen[hostcredential.FieldSecret] = struct{}{}
			}
		case "kind":
			if _, ok := fieldSeen[hostcredential.FieldKind]; !ok {
				selectedFields = append(selectedFields, hostcredential.FieldKind)
				fieldSeen[hostcredential.FieldKind] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		hc.Select(selectedFields...)
	}
	return nil
}

type hostcredentialPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []HostCredentialPaginateOption
}

func newHostCredentialPaginateArgs(rv map[string]any) *hostcredentialPaginateArgs {
	args := &hostcredentialPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*HostCredentialOrder:
			args.opts = append(args.opts, WithHostCredentialOrder(v))
		case []any:
			var orders []*HostCredentialOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &HostCredentialOrder{Field: &HostCredentialOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithHostCredentialOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*HostCredentialWhereInput); ok {
		args.opts = append(args.opts, WithHostCredentialFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (hf *HostFileQuery) CollectFields(ctx context.Context, satisfies ...string) (*HostFileQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return hf, nil
	}
	if err := hf.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return hf, nil
}

func (hf *HostFileQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(hostfile.Columns))
		selectedFields = []string{hostfile.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "host":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&HostClient{config: hf.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, hostImplementors)...); err != nil {
				return err
			}
			hf.withHost = query

		case "task":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: hf.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
				return err
			}
			hf.withTask = query
		case "createdAt":
			if _, ok := fieldSeen[hostfile.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, hostfile.FieldCreatedAt)
				fieldSeen[hostfile.FieldCreatedAt] = struct{}{}
			}
		case "lastModifiedAt":
			if _, ok := fieldSeen[hostfile.FieldLastModifiedAt]; !ok {
				selectedFields = append(selectedFields, hostfile.FieldLastModifiedAt)
				fieldSeen[hostfile.FieldLastModifiedAt] = struct{}{}
			}
		case "path":
			if _, ok := fieldSeen[hostfile.FieldPath]; !ok {
				selectedFields = append(selectedFields, hostfile.FieldPath)
				fieldSeen[hostfile.FieldPath] = struct{}{}
			}
		case "owner":
			if _, ok := fieldSeen[hostfile.FieldOwner]; !ok {
				selectedFields = append(selectedFields, hostfile.FieldOwner)
				fieldSeen[hostfile.FieldOwner] = struct{}{}
			}
		case "group":
			if _, ok := fieldSeen[hostfile.FieldGroup]; !ok {
				selectedFields = append(selectedFields, hostfile.FieldGroup)
				fieldSeen[hostfile.FieldGroup] = struct{}{}
			}
		case "permissions":
			if _, ok := fieldSeen[hostfile.FieldPermissions]; !ok {
				selectedFields = append(selectedFields, hostfile.FieldPermissions)
				fieldSeen[hostfile.FieldPermissions] = struct{}{}
			}
		case "size":
			if _, ok := fieldSeen[hostfile.FieldSize]; !ok {
				selectedFields = append(selectedFields, hostfile.FieldSize)
				fieldSeen[hostfile.FieldSize] = struct{}{}
			}
		case "hash":
			if _, ok := fieldSeen[hostfile.FieldHash]; !ok {
				selectedFields = append(selectedFields, hostfile.FieldHash)
				fieldSeen[hostfile.FieldHash] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		hf.Select(selectedFields...)
	}
	return nil
}

type hostfilePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []HostFilePaginateOption
}

func newHostFilePaginateArgs(rv map[string]any) *hostfilePaginateArgs {
	args := &hostfilePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*HostFileOrder:
			args.opts = append(args.opts, WithHostFileOrder(v))
		case []any:
			var orders []*HostFileOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &HostFileOrder{Field: &HostFileOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithHostFileOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*HostFileWhereInput); ok {
		args.opts = append(args.opts, WithHostFileFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (hp *HostProcessQuery) CollectFields(ctx context.Context, satisfies ...string) (*HostProcessQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return hp, nil
	}
	if err := hp.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return hp, nil
}

func (hp *HostProcessQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(hostprocess.Columns))
		selectedFields = []string{hostprocess.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "host":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&HostClient{config: hp.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, hostImplementors)...); err != nil {
				return err
			}
			hp.withHost = query

		case "task":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: hp.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
				return err
			}
			hp.withTask = query
		case "createdAt":
			if _, ok := fieldSeen[hostprocess.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, hostprocess.FieldCreatedAt)
				fieldSeen[hostprocess.FieldCreatedAt] = struct{}{}
			}
		case "lastModifiedAt":
			if _, ok := fieldSeen[hostprocess.FieldLastModifiedAt]; !ok {
				selectedFields = append(selectedFields, hostprocess.FieldLastModifiedAt)
				fieldSeen[hostprocess.FieldLastModifiedAt] = struct{}{}
			}
		case "pid":
			if _, ok := fieldSeen[hostprocess.FieldPid]; !ok {
				selectedFields = append(selectedFields, hostprocess.FieldPid)
				fieldSeen[hostprocess.FieldPid] = struct{}{}
			}
		case "ppid":
			if _, ok := fieldSeen[hostprocess.FieldPpid]; !ok {
				selectedFields = append(selectedFields, hostprocess.FieldPpid)
				fieldSeen[hostprocess.FieldPpid] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[hostprocess.FieldName]; !ok {
				selectedFields = append(selectedFields, hostprocess.FieldName)
				fieldSeen[hostprocess.FieldName] = struct{}{}
			}
		case "principal":
			if _, ok := fieldSeen[hostprocess.FieldPrincipal]; !ok {
				selectedFields = append(selectedFields, hostprocess.FieldPrincipal)
				fieldSeen[hostprocess.FieldPrincipal] = struct{}{}
			}
		case "path":
			if _, ok := fieldSeen[hostprocess.FieldPath]; !ok {
				selectedFields = append(selectedFields, hostprocess.FieldPath)
				fieldSeen[hostprocess.FieldPath] = struct{}{}
			}
		case "cmd":
			if _, ok := fieldSeen[hostprocess.FieldCmd]; !ok {
				selectedFields = append(selectedFields, hostprocess.FieldCmd)
				fieldSeen[hostprocess.FieldCmd] = struct{}{}
			}
		case "env":
			if _, ok := fieldSeen[hostprocess.FieldEnv]; !ok {
				selectedFields = append(selectedFields, hostprocess.FieldEnv)
				fieldSeen[hostprocess.FieldEnv] = struct{}{}
			}
		case "cwd":
			if _, ok := fieldSeen[hostprocess.FieldCwd]; !ok {
				selectedFields = append(selectedFields, hostprocess.FieldCwd)
				fieldSeen[hostprocess.FieldCwd] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[hostprocess.FieldStatus]; !ok {
				selectedFields = append(selectedFields, hostprocess.FieldStatus)
				fieldSeen[hostprocess.FieldStatus] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		hp.Select(selectedFields...)
	}
	return nil
}

type hostprocessPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []HostProcessPaginateOption
}

func newHostProcessPaginateArgs(rv map[string]any) *hostprocessPaginateArgs {
	args := &hostprocessPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*HostProcessOrder:
			args.opts = append(args.opts, WithHostProcessOrder(v))
		case []any:
			var orders []*HostProcessOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &HostProcessOrder{Field: &HostProcessOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithHostProcessOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*HostProcessWhereInput); ok {
		args.opts = append(args.opts, WithHostProcessFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (po *PortalQuery) CollectFields(ctx context.Context, satisfies ...string) (*PortalQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return po, nil
	}
	if err := po.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return po, nil
}

func (po *PortalQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(portal.Columns))
		selectedFields = []string{portal.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "task":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: po.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
				return err
			}
			po.withTask = query

		case "beacon":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&BeaconClient{config: po.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, beaconImplementors)...); err != nil {
				return err
			}
			po.withBeacon = query

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: po.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			po.withOwner = query

		case "activeUsers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: po.config}).Query()
			)
			args := newUserPaginateArgs(fieldArgs(ctx, new(UserWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newUserPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					po.loadTotal = append(po.loadTotal, func(ctx context.Context, nodes []*Portal) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"portal_active_users"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(portal.ActiveUsersColumn), ids...))
						})
						if err := query.GroupBy(portal.ActiveUsersColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					po.loadTotal = append(po.loadTotal, func(_ context.Context, nodes []*Portal) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ActiveUsers)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(portal.ActiveUsersColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			po.WithNamedActiveUsers(alias, func(wq *UserQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[portal.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, portal.FieldCreatedAt)
				fieldSeen[portal.FieldCreatedAt] = struct{}{}
			}
		case "lastModifiedAt":
			if _, ok := fieldSeen[portal.FieldLastModifiedAt]; !ok {
				selectedFields = append(selectedFields, portal.FieldLastModifiedAt)
				fieldSeen[portal.FieldLastModifiedAt] = struct{}{}
			}
		case "closedAt":
			if _, ok := fieldSeen[portal.FieldClosedAt]; !ok {
				selectedFields = append(selectedFields, portal.FieldClosedAt)
				fieldSeen[portal.FieldClosedAt] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		po.Select(selectedFields...)
	}
	return nil
}

type portalPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []PortalPaginateOption
}

func newPortalPaginateArgs(rv map[string]any) *portalPaginateArgs {
	args := &portalPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*PortalOrder:
			args.opts = append(args.opts, WithPortalOrder(v))
		case []any:
			var orders []*PortalOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &PortalOrder{Field: &PortalOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithPortalOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*PortalWhereInput); ok {
		args.opts = append(args.opts, WithPortalFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (q *QuestQuery) CollectFields(ctx context.Context, satisfies ...string) (*QuestQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return q, nil
	}
	if err := q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return q, nil
}

func (q *QuestQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(quest.Columns))
		selectedFields = []string{quest.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "tome":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TomeClient{config: q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, tomeImplementors)...); err != nil {
				return err
			}
			q.withTome = query

		case "bundle":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
				return err
			}
			q.withBundle = query

		case "tasks":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: q.config}).Query()
			)
			args := newTaskPaginateArgs(fieldArgs(ctx, new(TaskWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTaskPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					q.loadTotal = append(q.loadTotal, func(ctx context.Context, nodes []*Quest) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"quest_tasks"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(quest.TasksColumn), ids...))
						})
						if err := query.GroupBy(quest.TasksColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					q.loadTotal = append(q.loadTotal, func(_ context.Context, nodes []*Quest) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tasks)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(quest.TasksColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			q.WithNamedTasks(alias, func(wq *TaskQuery) {
				*wq = *query
			})

		case "creator":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			q.withCreator = query
		case "createdAt":
			if _, ok := fieldSeen[quest.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, quest.FieldCreatedAt)
				fieldSeen[quest.FieldCreatedAt] = struct{}{}
			}
		case "lastModifiedAt":
			if _, ok := fieldSeen[quest.FieldLastModifiedAt]; !ok {
				selectedFields = append(selectedFields, quest.FieldLastModifiedAt)
				fieldSeen[quest.FieldLastModifiedAt] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[quest.FieldName]; !ok {
				selectedFields = append(selectedFields, quest.FieldName)
				fieldSeen[quest.FieldName] = struct{}{}
			}
		case "parameters":
			if _, ok := fieldSeen[quest.FieldParameters]; !ok {
				selectedFields = append(selectedFields, quest.FieldParameters)
				fieldSeen[quest.FieldParameters] = struct{}{}
			}
		case "paramDefsAtCreation":
			if _, ok := fieldSeen[quest.FieldParamDefsAtCreation]; !ok {
				selectedFields = append(selectedFields, quest.FieldParamDefsAtCreation)
				fieldSeen[quest.FieldParamDefsAtCreation] = struct{}{}
			}
		case "eldritchAtCreation":
			if _, ok := fieldSeen[quest.FieldEldritchAtCreation]; !ok {
				selectedFields = append(selectedFields, quest.FieldEldritchAtCreation)
				fieldSeen[quest.FieldEldritchAtCreation] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		q.Select(selectedFields...)
	}
	return nil
}

type questPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []QuestPaginateOption
}

func newQuestPaginateArgs(rv map[string]any) *questPaginateArgs {
	args := &questPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*QuestOrder:
			args.opts = append(args.opts, WithQuestOrder(v))
		case []any:
			var orders []*QuestOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &QuestOrder{Field: &QuestOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithQuestOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*QuestWhereInput); ok {
		args.opts = append(args.opts, WithQuestFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (r *RepositoryQuery) CollectFields(ctx context.Context, satisfies ...string) (*RepositoryQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return r, nil
	}
	if err := r.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return r, nil
}

func (r *RepositoryQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(repository.Columns))
		selectedFields = []string{repository.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "tomes":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TomeClient{config: r.config}).Query()
			)
			args := newTomePaginateArgs(fieldArgs(ctx, new(TomeWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTomePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					r.loadTotal = append(r.loadTotal, func(ctx context.Context, nodes []*Repository) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"tome_repository"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(repository.TomesColumn), ids...))
						})
						if err := query.GroupBy(repository.TomesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				} else {
					r.loadTotal = append(r.loadTotal, func(_ context.Context, nodes []*Repository) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tomes)
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, tomeImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(repository.TomesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			r.WithNamedTomes(alias, func(wq *TomeQuery) {
				*wq = *query
			})

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: r.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			r.withOwner = query
		case "createdAt":
			if _, ok := fieldSeen[repository.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, repository.FieldCreatedAt)
				fieldSeen[repository.FieldCreatedAt] = struct{}{}
			}
		case "lastModifiedAt":
			if _, ok := fieldSeen[repository.FieldLastModifiedAt]; !ok {
				selectedFields = append(selectedFields, repository.FieldLastModifiedAt)
				fieldSeen[repository.FieldLastModifiedAt] = struct{}{}
			}
		case "url":
			if _, ok := fieldSeen[repository.FieldURL]; !ok {
				selectedFields = append(selectedFields, repository.FieldURL)
				fieldSeen[repository.FieldURL] = struct{}{}
			}
		case "publicKey":
			if _, ok := fieldSeen[repository.FieldPublicKey]; !ok {
				selectedFields = append(selectedFields, repository.FieldPublicKey)
				fieldSeen[repository.FieldPublicKey] = struct{}{}
			}
		case "lastImportedAt":
			if _, ok := fieldSeen[repository.FieldLastImportedAt]; !ok {
				selectedFields = append(selectedFields, repository.FieldLastImportedAt)
				fieldSeen[repository.FieldLastImportedAt] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		r.Select(selectedFields...)
	}
	return nil
}

type repositoryPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []RepositoryPaginateOption
}

func newRepositoryPaginateArgs(rv map[string]any) *repositoryPaginateArgs {
	args := &repositoryPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*RepositoryOrder:
			args.opts = append(args.opts, WithRepositoryOrder(v))
		case []any:
			var orders []*RepositoryOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &RepositoryOrder{Field: &RepositoryOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithRepositoryOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*RepositoryWhereInput); ok {
		args.opts = append(args.opts, WithRepositoryFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (s *ShellQuery) CollectFields(ctx context.Context, satisfies ...string) (*ShellQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return s, nil
	}
	if err := s.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return s, nil
}

func (s *ShellQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(shell.Columns))
		selectedFields = []string{shell.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "task":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TaskClient{config: s.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, taskImplementors)...); err != nil {
				return err
			}
			s.withTask = query

		case "beacon":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&BeaconClient{config: s.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, beaconImplementors)...); err != nil {
				return err
			}
			s.withBeacon = query

		case "owner":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: s.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			s.withOwner = query

		case "activeUsers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: s.config}).Query()
			)
			args := newUserPaginateArgs(fieldArgs(ctx, new(UserWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newUserPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					s.loadTotal = append(s.loadTotal, func(ctx context.Context, nodes []*Shell) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"shell_id"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(shell.ActiveUsersTable)
							s.Join(joinT).On(s.C(user.FieldID), joinT.C(shell.ActiveUsersPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(shell.ActiveUsersPrimaryKey[0]), ids...))
							s.Select(joinT.C(shell.ActiveUsersPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(shell.ActiveUsersPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					s.loadTotal = append(s.loadTotal, func(_ context.Context, nodes []*Shell) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ActiveUsers)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(shell.ActiveUsersPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			s.WithNamedActiveUsers(alias, func(wq *UserQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[shell.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, shell.FieldCreatedAt)
				fieldSeen[shell.FieldCreatedAt] = struct{}{}
			}
		case "lastModifiedAt":
			if _, ok := fieldSeen[shell.FieldLastModifiedAt]; !ok {
				selectedFields = append(selectedFields, shell.FieldLastModifiedAt)
				fieldSeen[shell.FieldLastModifiedAt] = struct{}{}
			}
		case "closedAt":
			if _, ok := fieldSeen[shell.FieldClosedAt]; !ok {
				selectedFields = append(selectedFields, shell.FieldClosedAt)
				fieldSeen[shell.FieldClosedAt] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		s.Select(selectedFields...)
	}
	return nil
}

type shellPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ShellPaginateOption
}

func newShellPaginateArgs(rv map[string]any) *shellPaginateArgs {
	args := &shellPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*ShellOrder:
			args.opts = append(args.opts, WithShellOrder(v))
		case []any:
			var orders []*ShellOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &ShellOrder{Field: &ShellOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithShellOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*ShellWhereInput); ok {
		args.opts = append(args.opts, WithShellFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (t *TagQuery) CollectFields(ctx context.Context, satisfies ...string) (*TagQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return t, nil
	}
	if err := t.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return t, nil
}

func (t *TagQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(tag.Columns))
		selectedFields = []string{tag.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "hosts":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&HostClient{config: t.config}).Query()
			)
			args := newHostPaginateArgs(fieldArgs(ctx, new(HostWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newHostPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					t.loadTotal = append(t.loadTotal, func(ctx context.Context, nodes []*Tag) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"tag_id"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(tag.HostsTable)
							s.Join(joinT).On(s.C(host.FieldID), joinT.C(tag.HostsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(tag.HostsPrimaryKey[1]), ids...))
							s.Select(joinT.C(tag.HostsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(tag.HostsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				} else {
					t.loadTotal = append(t.loadTotal, func(_ context.Context, nodes []*Tag) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Hosts)
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, hostImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(tag.HostsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			t.WithNamedHosts(alias, func(wq *HostQuery) {
				*wq = *query
			})
		case "name":
			if _, ok := fieldSeen[tag.FieldName]; !ok {
				selectedFields = append(selectedFields, tag.FieldName)
				fieldSeen[tag.FieldName] = struct{}{}
			}
		case "kind":
			if _, ok := fieldSeen[tag.FieldKind]; !ok {
				selectedFields = append(selectedFields, tag.FieldKind)
				fieldSeen[tag.FieldKind] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		t.Select(selectedFields...)
	}
	return nil
}

type tagPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TagPaginateOption
}

func newTagPaginateArgs(rv map[string]any) *tagPaginateArgs {
	args := &tagPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*TagOrder:
			args.opts = append(args.opts, WithTagOrder(v))
		case []any:
			var orders []*TagOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &TagOrder{Field: &TagOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithTagOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*TagWhereInput); ok {
		args.opts = append(args.opts, WithTagFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (t *TaskQuery) CollectFields(ctx context.Context, satisfies ...string) (*TaskQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return t, nil
	}
	if err := t.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return t, nil
}

func (t *TaskQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(task.Columns))
		selectedFields = []string{task.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "quest":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&QuestClient{config: t.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, questImplementors)...); err != nil {
				return err
			}
			t.withQuest = query

		case "beacon":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&BeaconClient{config: t.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, beaconImplementors)...); err != nil {
				return err
			}
			t.withBeacon = query

		case "reportedFiles":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&HostFileClient{config: t.config}).Query()
			)
			args := newHostFilePaginateArgs(fieldArgs(ctx, new(HostFileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newHostFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					t.loadTotal = append(t.loadTotal, func(ctx context.Context, nodes []*Task) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"task_reported_files"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(task.ReportedFilesColumn), ids...))
						})
						if err := query.GroupBy(task.ReportedFilesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					t.loadTotal = append(t.loadTotal, func(_ context.Context, nodes []*Task) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ReportedFiles)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, hostfileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(task.ReportedFilesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			t.WithNamedReportedFiles(alias, func(wq *HostFileQuery) {
				*wq = *query
			})

		case "reportedProcesses":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&HostProcessClient{config: t.config}).Query()
			)
			args := newHostProcessPaginateArgs(fieldArgs(ctx, new(HostProcessWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newHostProcessPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					t.loadTotal = append(t.loadTotal, func(ctx context.Context, nodes []*Task) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"task_reported_processes"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(task.ReportedProcessesColumn), ids...))
						})
						if err := query.GroupBy(task.ReportedProcessesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					t.loadTotal = append(t.loadTotal, func(_ context.Context, nodes []*Task) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ReportedProcesses)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, hostprocessImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(task.ReportedProcessesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			t.WithNamedReportedProcesses(alias, func(wq *HostProcessQuery) {
				*wq = *query
			})

		case "reportedCredentials":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&HostCredentialClient{config: t.config}).Query()
			)
			args := newHostCredentialPaginateArgs(fieldArgs(ctx, new(HostCredentialWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newHostCredentialPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					t.loadTotal = append(t.loadTotal, func(ctx context.Context, nodes []*Task) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"task_reported_credentials"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(task.ReportedCredentialsColumn), ids...))
						})
						if err := query.GroupBy(task.ReportedCredentialsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					t.loadTotal = append(t.loadTotal, func(_ context.Context, nodes []*Task) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ReportedCredentials)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, hostcredentialImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(task.ReportedCredentialsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			t.WithNamedReportedCredentials(alias, func(wq *HostCredentialQuery) {
				*wq = *query
			})

		case "shells":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ShellClient{config: t.config}).Query()
			)
			args := newShellPaginateArgs(fieldArgs(ctx, new(ShellWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newShellPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					t.loadTotal = append(t.loadTotal, func(ctx context.Context, nodes []*Task) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"shell_task"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(task.ShellsColumn), ids...))
						})
						if err := query.GroupBy(task.ShellsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					t.loadTotal = append(t.loadTotal, func(_ context.Context, nodes []*Task) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Shells)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, shellImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(task.ShellsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			t.WithNamedShells(alias, func(wq *ShellQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[task.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, task.FieldCreatedAt)
				fieldSeen[task.FieldCreatedAt] = struct{}{}
			}
		case "lastModifiedAt":
			if _, ok := fieldSeen[task.FieldLastModifiedAt]; !ok {
				selectedFields = append(selectedFields, task.FieldLastModifiedAt)
				fieldSeen[task.FieldLastModifiedAt] = struct{}{}
			}
		case "claimedAt":
			if _, ok := fieldSeen[task.FieldClaimedAt]; !ok {
				selectedFields = append(selectedFields, task.FieldClaimedAt)
				fieldSeen[task.FieldClaimedAt] = struct{}{}
			}
		case "execStartedAt":
			if _, ok := fieldSeen[task.FieldExecStartedAt]; !ok {
				selectedFields = append(selectedFields, task.FieldExecStartedAt)
				fieldSeen[task.FieldExecStartedAt] = struct{}{}
			}
		case "execFinishedAt":
			if _, ok := fieldSeen[task.FieldExecFinishedAt]; !ok {
				selectedFields = append(selectedFields, task.FieldExecFinishedAt)
				fieldSeen[task.FieldExecFinishedAt] = struct{}{}
			}
		case "output":
			if _, ok := fieldSeen[task.FieldOutput]; !ok {
				selectedFields = append(selectedFields, task.FieldOutput)
				fieldSeen[task.FieldOutput] = struct{}{}
			}
		case "outputSize":
			if _, ok := fieldSeen[task.FieldOutputSize]; !ok {
				selectedFields = append(selectedFields, task.FieldOutputSize)
				fieldSeen[task.FieldOutputSize] = struct{}{}
			}
		case "error":
			if _, ok := fieldSeen[task.FieldError]; !ok {
				selectedFields = append(selectedFields, task.FieldError)
				fieldSeen[task.FieldError] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		t.Select(selectedFields...)
	}
	return nil
}

type taskPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TaskPaginateOption
}

func newTaskPaginateArgs(rv map[string]any) *taskPaginateArgs {
	args := &taskPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*TaskOrder:
			args.opts = append(args.opts, WithTaskOrder(v))
		case []any:
			var orders []*TaskOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &TaskOrder{Field: &TaskOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithTaskOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*TaskWhereInput); ok {
		args.opts = append(args.opts, WithTaskFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (t *TomeQuery) CollectFields(ctx context.Context, satisfies ...string) (*TomeQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return t, nil
	}
	if err := t.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return t, nil
}

func (t *TomeQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(tome.Columns))
		selectedFields = []string{tome.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "files":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&FileClient{config: t.config}).Query()
			)
			args := newFilePaginateArgs(fieldArgs(ctx, new(FileWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newFilePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					t.loadTotal = append(t.loadTotal, func(ctx context.Context, nodes []*Tome) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"tome_id"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(tome.FilesTable)
							s.Join(joinT).On(s.C(file.FieldID), joinT.C(tome.FilesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(tome.FilesPrimaryKey[0]), ids...))
							s.Select(joinT.C(tome.FilesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(tome.FilesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				} else {
					t.loadTotal = append(t.loadTotal, func(_ context.Context, nodes []*Tome) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Files)
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, fileImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(tome.FilesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			t.WithNamedFiles(alias, func(wq *FileQuery) {
				*wq = *query
			})

		case "uploader":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: t.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			t.withUploader = query

		case "repository":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RepositoryClient{config: t.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, repositoryImplementors)...); err != nil {
				return err
			}
			t.withRepository = query
		case "createdAt":
			if _, ok := fieldSeen[tome.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, tome.FieldCreatedAt)
				fieldSeen[tome.FieldCreatedAt] = struct{}{}
			}
		case "lastModifiedAt":
			if _, ok := fieldSeen[tome.FieldLastModifiedAt]; !ok {
				selectedFields = append(selectedFields, tome.FieldLastModifiedAt)
				fieldSeen[tome.FieldLastModifiedAt] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[tome.FieldName]; !ok {
				selectedFields = append(selectedFields, tome.FieldName)
				fieldSeen[tome.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[tome.FieldDescription]; !ok {
				selectedFields = append(selectedFields, tome.FieldDescription)
				fieldSeen[tome.FieldDescription] = struct{}{}
			}
		case "author":
			if _, ok := fieldSeen[tome.FieldAuthor]; !ok {
				selectedFields = append(selectedFields, tome.FieldAuthor)
				fieldSeen[tome.FieldAuthor] = struct{}{}
			}
		case "supportModel":
			if _, ok := fieldSeen[tome.FieldSupportModel]; !ok {
				selectedFields = append(selectedFields, tome.FieldSupportModel)
				fieldSeen[tome.FieldSupportModel] = struct{}{}
			}
		case "tactic":
			if _, ok := fieldSeen[tome.FieldTactic]; !ok {
				selectedFields = append(selectedFields, tome.FieldTactic)
				fieldSeen[tome.FieldTactic] = struct{}{}
			}
		case "paramDefs":
			if _, ok := fieldSeen[tome.FieldParamDefs]; !ok {
				selectedFields = append(selectedFields, tome.FieldParamDefs)
				fieldSeen[tome.FieldParamDefs] = struct{}{}
			}
		case "eldritch":
			if _, ok := fieldSeen[tome.FieldEldritch]; !ok {
				selectedFields = append(selectedFields, tome.FieldEldritch)
				fieldSeen[tome.FieldEldritch] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		t.Select(selectedFields...)
	}
	return nil
}

type tomePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TomePaginateOption
}

func newTomePaginateArgs(rv map[string]any) *tomePaginateArgs {
	args := &tomePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*TomeOrder:
			args.opts = append(args.opts, WithTomeOrder(v))
		case []any:
			var orders []*TomeOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &TomeOrder{Field: &TomeOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithTomeOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*TomeWhereInput); ok {
		args.opts = append(args.opts, WithTomeFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (u *UserQuery) CollectFields(ctx context.Context, satisfies ...string) (*UserQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return u, nil
	}
	if err := u.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return u, nil
}

func (u *UserQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(user.Columns))
		selectedFields = []string{user.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "tomes":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TomeClient{config: u.config}).Query()
			)
			args := newTomePaginateArgs(fieldArgs(ctx, new(TomeWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTomePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					u.loadTotal = append(u.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"tome_uploader"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(user.TomesColumn), ids...))
						})
						if err := query.GroupBy(user.TomesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				} else {
					u.loadTotal = append(u.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Tomes)
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, tomeImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.TomesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			u.WithNamedTomes(alias, func(wq *TomeQuery) {
				*wq = *query
			})

		case "activeShells":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ShellClient{config: u.config}).Query()
			)
			args := newShellPaginateArgs(fieldArgs(ctx, new(ShellWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newShellPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					u.loadTotal = append(u.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"user_id"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(user.ActiveShellsTable)
							s.Join(joinT).On(s.C(shell.FieldID), joinT.C(user.ActiveShellsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(user.ActiveShellsPrimaryKey[1]), ids...))
							s.Select(joinT.C(user.ActiveShellsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(user.ActiveShellsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					u.loadTotal = append(u.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ActiveShells)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, shellImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.ActiveShellsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			u.WithNamedActiveShells(alias, func(wq *ShellQuery) {
				*wq = *query
			})
		case "name":
			if _, ok := fieldSeen[user.FieldName]; !ok {
				selectedFields = append(selectedFields, user.FieldName)
				fieldSeen[user.FieldName] = struct{}{}
			}
		case "photoURL":
			if _, ok := fieldSeen[user.FieldPhotoURL]; !ok {
				selectedFields = append(selectedFields, user.FieldPhotoURL)
				fieldSeen[user.FieldPhotoURL] = struct{}{}
			}
		case "isActivated":
			if _, ok := fieldSeen[user.FieldIsActivated]; !ok {
				selectedFields = append(selectedFields, user.FieldIsActivated)
				fieldSeen[user.FieldIsActivated] = struct{}{}
			}
		case "isAdmin":
			if _, ok := fieldSeen[user.FieldIsAdmin]; !ok {
				selectedFields = append(selectedFields, user.FieldIsAdmin)
				fieldSeen[user.FieldIsAdmin] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		u.Select(selectedFields...)
	}
	return nil
}

type userPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []UserPaginateOption
}

func newUserPaginateArgs(rv map[string]any) *userPaginateArgs {
	args := &userPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case []*UserOrder:
			args.opts = append(args.opts, WithUserOrder(v))
		case []any:
			var orders []*UserOrder
			for i := range v {
				mv, ok := v[i].(map[string]any)
				if !ok {
					continue
				}
				var (
					err1, err2 error
					order      = &UserOrder{Field: &UserOrderField{}, Direction: entgql.OrderDirectionAsc}
				)
				if d, ok := mv[directionField]; ok {
					err1 = order.Direction.UnmarshalGQL(d)
				}
				if f, ok := mv[fieldField]; ok {
					err2 = order.Field.UnmarshalGQL(f)
				}
				if err1 == nil && err2 == nil {
					orders = append(orders, order)
				}
			}
			args.opts = append(args.opts, WithUserOrder(orders))
		}
	}
	if v, ok := rv[whereField].(*UserWhereInput); ok {
		args.opts = append(args.opts, WithUserFilter(v.Filter))
	}
	return args
}

const (
	afterField     = "after"
	firstField     = "first"
	beforeField    = "before"
	lastField      = "last"
	orderByField   = "orderBy"
	directionField = "direction"
	fieldField     = "field"
	whereField     = "where"
)

func fieldArgs(ctx context.Context, whereInput any, path ...string) map[string]any {
	field := collectedField(ctx, path...)
	if field == nil || field.Arguments == nil {
		return nil
	}
	oc := graphql.GetOperationContext(ctx)
	args := field.ArgumentMap(oc.Variables)
	return unmarshalArgs(ctx, whereInput, args)
}

// unmarshalArgs allows extracting the field arguments from their raw representation.
func unmarshalArgs(ctx context.Context, whereInput any, args map[string]any) map[string]any {
	for _, k := range []string{firstField, lastField} {
		v, ok := args[k]
		if !ok {
			continue
		}
		i, err := graphql.UnmarshalInt(v)
		if err == nil {
			args[k] = &i
		}
	}
	for _, k := range []string{beforeField, afterField} {
		v, ok := args[k]
		if !ok {
			continue
		}
		c := &Cursor{}
		if c.UnmarshalGQL(v) == nil {
			args[k] = c
		}
	}
	if v, ok := args[whereField]; ok && whereInput != nil {
		if err := graphql.UnmarshalInputFromContext(ctx, v, whereInput); err == nil {
			args[whereField] = whereInput
		}
	}

	return args
}

// mayAddCondition appends another type condition to the satisfies list
// if it does not exist in the list.
func mayAddCondition(satisfies []string, typeCond []string) []string {
Cond:
	for _, c := range typeCond {
		for _, s := range satisfies {
			if c == s {
				continue Cond
			}
		}
		satisfies = append(satisfies, c)
	}
	return satisfies
}
